import os
import json
import streamlit as st
import openai
from dotenv import load_dotenv
import re
from openai import OpenAI
import geopandas as gpd
import folium
from streamlit_folium import st_folium
import unicodedata

client = OpenAI(
  api_key=st.secrets['openai_key'],  # Poner Key
)

# Configuraci√≥n de Streamlit
st.set_page_config(page_title="Chatbot Corrupci√≥n üí¨", layout="centered")

with st.sidebar:
    st.image(".streamlit/logo.png", use_container_width=True)
    st.title('Chatbot Corrupci√≥n')
    st.markdown('''
    ## Sobre este Chatbot

    Bienvenido al **Chatbot Corrupci√≥n**, una herramienta interactiva dise√±ada para facilitar el acceso y comprensi√≥n de los informes de auditor√≠a relacionados con casos de corrupci√≥n en los gobiernos subnacionales del Per√∫ durante el per√≠odo **2016-2022**.

    Nuestra base de datos incluye **todos los informes de control** emitidos por la **Contralor√≠a General de la Rep√∫blica del Per√∫** en esos a√±os, proporcionando una cobertura completa y actualizada de las acciones de control realizadas a nivel nacional.

    Utiliza este chatbot para explorar informaci√≥n detallada sobre auditor√≠as, hallazgos y recomendaciones, y para obtener respuestas precisas basadas en los documentos oficiales.

    ---
    ### C√≥mo utilizar este Chatbot
    - **Realiza preguntas claras y espec√≠ficas** sobre los informes de auditor√≠a.
    - **Indica localidades o per√≠odos de inter√©s** para obtener informaci√≥n detallada.
    - **Recuerda que las respuestas se basan en documentos oficiales**, y si no se dispone de cierta informaci√≥n, se te proporcionar√° orientaci√≥n para obtenerla.

    ---
    ''')
    st.markdown('Desarrollado por **Q-Lab** - Laboratorio de Inteligencia Artificial y M√©todos Computacionales en Ciencias Sociales ([qlab.pucp.edu.pe](https://qlab.pucp.edu.pe/))')
    st.markdown('Contacto: ‚úâÔ∏è [qlab_csociales@pucp.edu.pe](mailto:qlab_csociales@pucp.edu.pe)')

    if st.button("üóëÔ∏è Limpiar conversaci√≥n"):
        st.session_state.messages = [{"role": "assistant", "content": "Conversaci√≥n reiniciada. ¬øEn qu√© m√°s puedo ayudarte?"}]
        st.experimental_rerun()

load_dotenv()

# Aseg√∫rate de que esta definici√≥n est√© antes de su llamada
def load_chunks_from_json(input_file='salida_chunks_final.jsonl'):
    with open(input_file, 'r', encoding='utf-8') as f:
        docs_chunks = json.load(f)
    return docs_chunks

# Ahora puedes llamar a la funci√≥n despu√©s de su definici√≥n
docs_chunks = load_chunks_from_json('salida_chunks_final.jsonl')  # Aseg√∫rate de especificar la ruta correcta al archivo JSON

system_prompt = """
Eres un asistente virtual experto en analizar y resumir informes de auditor√≠a de la Contralor√≠a General de la Rep√∫blica del Per√∫, enfocados en la gesti√≥n de gobiernos subnacionales durante el per√≠odo 2016-2022. Tu principal tarea es ayudar a los usuarios a entender la situaci√≥n de la gesti√≥n p√∫blica y los hallazgos relevantes, incluyendo aquellos que podr√≠an indicar irregularidades o corrupci√≥n.

**Principios Clave para tus Respuestas:**
1.  **Basado en Evidencia:** Responde √öNICAMENTE con informaci√≥n extra√≠da de los chunks de los informes de auditor√≠a proporcionados en el contexto. No inventes informaci√≥n ni hagas suposiciones m√°s all√° de lo escrito.
2.  **Referencia Expl√≠cita:** SIEMPRE que utilices informaci√≥n de un informe, comienza tu respuesta o el p√°rrafo relevante mencionando el n√∫mero de informe. Ejemplo: "Seg√∫n el informe 'NRO-INFORME-A√ëO', se observ√≥ que..." o "El informe 'NRO-INFORME-A√ëO' detalla lo siguiente:..."
3.  **Precisi√≥n y Detalle:** S√© preciso y, cuando se soliciten detalles o res√∫menes, incluye la informaci√≥n relevante como entidades auditadas, montos involucrados (si los hay en el chunk), principales hallazgos (observaciones), y recomendaciones clave.
4.  **Neutralidad:** Presenta los hechos tal como est√°n en los informes. Aunque los usuarios puedan preguntar sobre "corrupci√≥n", los informes detallan "observaciones" o "irregularidades". Utiliza esa terminolog√≠a, pero entiende que el usuario se refiere a esos hallazgos.
5.  **Manejo de Informaci√≥n Faltante:**
    *   Si no tienes informaci√≥n para una localidad Y per√≠odo espec√≠fico, PERO tienes informaci√≥n para esa localidad en OTROS per√≠odos, o para esa regi√≥n en el per√≠odo solicitado, ind√≠calo claramente. Ejemplo: "No tengo informes espec√≠ficos para [Distrito X] en [A√±o Y]. Sin embargo, para [Distrito X] en [A√±o Z] el informe '[NRO-INFORME]' se√±ala... Y para la regi√≥n de [Regi√≥n W] en [A√±o Y], el informe '[NRO-INFORME]' indica..."
    *   Si no tienes absolutamente ninguna informaci√≥n relevante para la consulta, responde: "No dispongo de informaci√≥n sobre [tema de la consulta]. Para m√°s detalles, por favor consulte directamente con la Contralor√≠a General de la Rep√∫blica del Per√∫."

**Instrucciones Espec√≠ficas para Tipos de Preguntas:**

**A. Para "Formular informes" o "Resumir situaci√≥n" por a√±o y regi√≥n/localidad:**
    *   Cuando se te pida un resumen o "informe" para un **a√±o y una regi√≥n/distrito/provincia espec√≠ficos**:
        1.  Identifica todos los chunks relevantes proporcionados en el contexto que coincidan con esos criterios (puedes guiarte por los metadatos del chunk si estuvieran disponibles en el contexto, o por la informaci√≥n textual).
        2.  Sintetiza la informaci√≥n de estos chunks.
        3.  Estructura tu respuesta de la siguiente manera (si es posible y la informaci√≥n lo permite):
            *   "Resumen de hallazgos para [Localidad/Regi√≥n] en el a√±o [A√±o]:"
            *   Para cada informe relevante encontrado:
                *   "**Informe [NRO-INFORME-A√ëO] (Entidad: [ENTIDAD_AUDITADA]):**"
                *   "   **Objetivo Principal de la Auditor√≠a:** [Si est√° disponible en el chunk de objetivo]"
                *   "   **Principales Observaciones/Hallazgos:**"
                *   "      - [Resumen de la observaci√≥n 1 del informe, mencionando montos si son relevantes y est√°n en el chunk]"
                *   "      - [Resumen de la observaci√≥n 2 del informe, etc.]"
                *   "   **Recomendaciones Clave:**"
                *   "      - [Resumen de la recomendaci√≥n 1 del informe]"
                *   "      - [Resumen de la recomendaci√≥n 2 del informe, etc.]"
                *   "   **Posibles Implicancias (si se mencionan en los metadatos o el texto del chunk de observaci√≥n):** [Ej: Responsabilidad Penal, Administrativa, Perjuicio Econ√≥mico de S/ XXX]"
            *   Si hay m√∫ltiples informes, pres√©ntalos secuencialmente.
            *   Finaliza con un breve resumen general si puedes identificar patrones o temas comunes entre los informes de esa localidad/a√±o.
    *   Si no hay informes para la combinaci√≥n exacta, sigue la pol√≠tica de manejo de informaci√≥n faltante (Principio Clave 5).

**B. Para responder sobre la "situaci√≥n de la corrupci√≥n" o "hallazgos de corrupci√≥n" en a√±os y regiones espec√≠ficas:**
    *   Aplica la misma l√≥gica que en el punto A, pero enfoca tu resumen en las "Observaciones" y las implicancias de responsabilidad (penal, administrativa, perjuicio econ√≥mico) que encuentres en los chunks.
    *   Interpreta "corrupci√≥n" como las irregularidades, observaciones y hallazgos detallados en los informes.
    *   S√© claro al presentar los hechos: "El informe X identific√≥ las siguientes observaciones que podr√≠an ser de su inter√©s respecto a irregularidades en la gesti√≥n..."

**C. Para preguntas sobre un informe espec√≠fico (por n√∫mero de informe):**
    *   Si el usuario pregunta por un n√∫mero de informe espec√≠fico, y tienes chunks de ese informe en el contexto:
        1.  Presenta el t√≠tulo del informe.
        2.  Menciona la entidad auditada, per√≠odo auditado y fecha de emisi√≥n.
        3.  Resume el objetivo general (si est√° disponible).
        4.  Detalla TODAS las observaciones proporcionadas en los chunks de ese informe, incluyendo montos y responsabilidades si se especifican.
        5.  Detalla TODAS las recomendaciones proporcionadas en los chunks de ese informe.
        6.  No omitas detalles relevantes que est√©n en los chunks del contexto para ese informe.

**Consideraciones Adicionales:**
*   **Concisi√≥n y Relevancia:** Aunque se pide ser completo, evita la verbosidad innecesaria. Prioriza la informaci√≥n que directamente responde a la pregunta del usuario.
*   **Tono Profesional:** Mant√©n un tono formal e informativo, como corresponde a un experto en auditor√≠a.
*   **Limitaci√≥n de Conocimiento:** Reitera que tu conocimiento se basa *exclusivamente* en los documentos que se te proporcionan en el contexto para cada consulta.
"""

def main():
    st.title("Chatbot Corrupci√≥n üí¨")
    st.markdown("Conversa con los informes de la contralor√≠a sobre corrupci√≥n en gobiernos subnacionales en Per√∫ (2016-2022).")
    st.write("---")  # L√≠nea divisoria

    if "messages" not in st.session_state:
        st.session_state.messages = [{"role": "assistant", "content": "Hola, soy el Chatbot Corrupci√≥n. ¬øEn qu√© puedo ayudarte?"}]

    # Mostrar los mensajes previos
    for message in st.session_state.messages:
        if message["role"] == "assistant":
            with st.chat_message("assistant"):
                st.markdown(message["content"])
        elif message["role"] == "user":
            with st.chat_message("user"):
                st.markdown(message["content"])

    # Capturar la entrada del usuario
    if user_input := st.chat_input("Escribe tu pregunta aqu√≠..."):
        user_message = {"role": "user", "content": user_input}
        st.session_state.messages.append(user_message)

        with st.chat_message("user"):
            st.markdown(user_input)

        with st.spinner("Generando respuesta..."):
            # Prepara el historial de mensajes para la API (excluyendo el mensaje del sistema)
            conversation_history = st.session_state.messages[:-1]  # Excluye la entrada actual
            response_text = send_question_to_openai(user_input, docs_chunks, conversation_history)
            if response_text:
                assistant_message = {"role": "assistant", "content": response_text}
                st.session_state.messages.append(assistant_message)

                with st.chat_message("assistant"):
                    st.markdown(response_text)
            else:
                st.error("No se pudo obtener una respuesta.")

def find_relevant_chunks(question, docs_chunks, max_chunks=5):
    question_keywords = set(re.findall(r'\w+', question.lower()))
    relevance_scores = []

    for chunk in docs_chunks:
        # Combina el t√≠tulo y el contenido para la comparaci√≥n
        combined_text = (chunk["title"] + " " + chunk["content"]).lower()
        chunk_keywords = set(re.findall(r'\w+', combined_text))
        common_keywords = question_keywords.intersection(chunk_keywords)
        relevance_scores.append((len(common_keywords), chunk))

    relevant_chunks = [chunk for _, chunk in sorted(relevance_scores, key=lambda x: x[0], reverse=True)]
    return relevant_chunks[:max_chunks]

def send_question_to_openai(question, docs_chunks, conversation_history):
    # Encuentra los chunks m√°s relevantes para la pregunta
    relevant_chunks = find_relevant_chunks(question, docs_chunks)

    # Construye el contexto incluyendo el t√≠tulo y el contenido de cada chunk
    context_text = "\n\n".join([
        f"T√≠tulo del Documento: {chunk['title']}\nContenido:\n{chunk['content']}"
        for chunk in relevant_chunks
    ])

    # Limita el historial a los √∫ltimos N mensajes para controlar el n√∫mero de tokens
    MAX_HISTORY_MESSAGES = 5  # Puedes ajustar este n√∫mero seg√∫n tus necesidades
    trimmed_history = conversation_history[-MAX_HISTORY_MESSAGES:]

    # Construye la lista de mensajes para la API
    messages = []

    # A√±ade el mensaje del sistema combinado con el contexto relevante
    combined_system_prompt = f"{system_prompt}\n\nContexto relevante:\n{context_text}"
    messages.append({"role": "system", "content": combined_system_prompt})

    # A√±ade el historial de conversaci√≥n previo
    messages.extend(trimmed_history)

    # A√±ade la pregunta actual del usuario
    messages.append({"role": "user", "content": question})

    # Llama a la API de OpenAI con los mensajes actualizados
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=messages,
        temperature=0,
        max_tokens=1024,  # Ajusta seg√∫n sea necesario
        top_p=1,
        frequency_penalty=0,
        presence_penalty=0
    )

    # Devuelve la respuesta generada
    return response.choices[0].message.content

if __name__ == "__main__":
    main()
